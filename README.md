# SISTEMA_ANALITICA_EMI

Sistema de AnalÃ­tica de Datos utilizando tÃ©cnicas Open Source Intelligence (OSINT) para el Vicerrectorado de Grado de la Escuela Militar de IngenierÃ­a.

## ðŸ“‹ DescripciÃ³n

El proyecto desarrolla un sistema integral de analÃ­tica de datos que combina tÃ©cnicas OSINT con Inteligencia Artificial para automatizar la recolecciÃ³n, procesamiento y anÃ¡lisis de informaciÃ³n proveniente de fuentes abiertas. El sistema permite al Vicerrectorado de Grado optimizar la toma de decisiones acadÃ©micas mediante el anÃ¡lisis automatizado de patrones y tendencias.

## ðŸŽ¯ Objetivos

### Objetivo General
Desarrollar un sistema de analÃ­tica de datos utilizando tÃ©cnicas de Open Source Intelligence que permita la identificaciÃ³n de patrones para reducir tiempo en el flujo de informaciÃ³n y la toma de decisiones en el Vicerrectorado de Grado de la Escuela Militar de IngenierÃ­a.

### Objetivos EspecÃ­ficos
- Analizar datos provenientes de fuentes abiertas utilizando tÃ©cnicas OSINT
- DiseÃ±ar un mÃ³dulo de visualizaciÃ³n mediante dashboard interactivo
- Aplicar modelos de IA, Machine Learning y NLP para anÃ¡lisis de datos
- Evaluar el funcionamiento mediante pruebas de efectividad

## ðŸ—ï¸ Arquitectura del Sistema

El sistema se estructura en varios mÃ³dulos integrados:

### 1. MÃ³dulo de RecolecciÃ³n de Datos (OSINT)

```python
# Ejemplo de recolecciÃ³n de datos desde fuentes abiertas
import requests
from bs4 import BeautifulSoup
import pandas as pd

class OSINTCollector:
    def __init__(self, sources):
        self.sources = sources
        self.data = []
    
    def collect_social_media_data(self, platform_url):
        """
        Recolecta datos de plataformas de redes sociales
        usando APIs oficiales o web scraping Ã©tico
        """
        try:
            response = requests.get(platform_url)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ExtracciÃ³n de datos relevantes
            posts = soup.find_all('div', class_='post-content')
            
            for post in posts:
                self.data.append({
                    'content': post.text,
                    'timestamp': post.find('time')['datetime'],
                    'source': platform_url
                })
            
            return self.data
        except Exception as e:
            print(f"Error en recolecciÃ³n: {e}")
            return None
    
    def save_to_database(self, db_connection):
        """
        Almacena datos recolectados en base de datos
        """
        df = pd.DataFrame(self.data)
        df.to_sql('raw_data', db_connection, if_exists='append')
```

### 2. MÃ³dulo de Procesamiento con IA

```python
# AnÃ¡lisis de sentimientos con NLP
from transformers import pipeline
import numpy as np

class NLPAnalyzer:
    def __init__(self):
        self.sentiment_analyzer = pipeline(
            "sentiment-analysis",
            model="nlptown/bert-base-multilingual-uncased-sentiment"
        )
    
    def analyze_sentiment(self, texts):
        """
        Analiza el sentimiento de textos recolectados
        """
        results = []
        for text in texts:
            sentiment = self.sentiment_analyzer(text[:512])[0]
            results.append({
                'text': text,
                'label': sentiment['label'],
                'score': sentiment['score']
            })
        return results
    
    def detect_patterns(self, data):
        """
        Identifica patrones mediante Machine Learning
        """
        from sklearn.cluster import KMeans
        from sklearn.feature_extraction.text import TfidfVectorizer
        
        # VectorizaciÃ³n de textos
        vectorizer = TfidfVectorizer(max_features=100)
        X = vectorizer.fit_transform(data['content'])
        
        # Clustering para identificar temas
        kmeans = KMeans(n_clusters=5, random_state=42)
        clusters = kmeans.fit_predict(X)
        
        return clusters
```

### 3. Base de Datos

```sql
-- Estructura de base de datos PostgreSQL

-- Tabla de datos brutos recolectados
CREATE TABLE raw_data (
    id SERIAL PRIMARY KEY,
    content TEXT NOT NULL,
    source VARCHAR(255),
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    platform VARCHAR(100),
    metadata JSONB
);

-- Tabla de anÃ¡lisis procesados
CREATE TABLE processed_analysis (
    id SERIAL PRIMARY KEY,
    raw_data_id INTEGER REFERENCES raw_data(id),
    sentiment_score DECIMAL(3,2),
    sentiment_label VARCHAR(50),
    topic_cluster INTEGER,
    keywords TEXT[],
    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Tabla de alertas y patrones detectados
CREATE TABLE detected_patterns (
    id SERIAL PRIMARY KEY,
    pattern_type VARCHAR(100),
    description TEXT,
    severity_level VARCHAR(20),
    detected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    status VARCHAR(50) DEFAULT 'active',
    related_data_ids INTEGER[]
);

-- Vista para dashboard de mÃ©tricas
CREATE VIEW dashboard_metrics AS
SELECT 
    DATE(timestamp) as date,
    platform,
    COUNT(*) as total_mentions,
    AVG(pa.sentiment_score) as avg_sentiment,
    COUNT(DISTINCT dp.id) as patterns_detected
FROM raw_data rd
LEFT JOIN processed_analysis pa ON rd.id = pa.raw_data_id
LEFT JOIN detected_patterns dp ON rd.id = ANY(dp.related_data_ids)
GROUP BY DATE(timestamp), platform;

-- Ãndices para optimizaciÃ³n
CREATE INDEX idx_raw_data_timestamp ON raw_data(timestamp);
CREATE INDEX idx_raw_data_platform ON raw_data(platform);
CREATE INDEX idx_processed_analysis_sentiment ON processed_analysis(sentiment_label);
```

### 4. Dashboard de VisualizaciÃ³n

```python
# Dashboard interactivo con Streamlit
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta

class AnalyticsDashboard:
    def __init__(self, db_connection):
        self.db = db_connection
    
    def render_main_dashboard(self):
        st.title("ðŸ“Š Sistema de AnalÃ­tica OSINT - Vicerrectorado de Grado")
        
        # KPIs principales
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_data = self.get_total_records()
            st.metric("Total Datos Recolectados", total_data)
        
        with col2:
            avg_sentiment = self.get_average_sentiment()
            st.metric("Sentimiento Promedio", f"{avg_sentiment:.2f}")
        
        with col3:
            patterns = self.get_active_patterns()
            st.metric("Patrones Detectados", patterns)
        
        with col4:
            alerts = self.get_pending_alerts()
            st.metric("Alertas Pendientes", alerts, delta="-2")
        
        # GrÃ¡ficos de tendencias
        self.render_sentiment_timeline()
        self.render_topic_distribution()
        self.render_pattern_alerts()
    
    def render_sentiment_timeline(self):
        """
        Visualiza evoluciÃ³n del sentimiento en el tiempo
        """
        query = """
            SELECT DATE(rd.timestamp) as date,
                   AVG(pa.sentiment_score) as avg_score
            FROM raw_data rd
            JOIN processed_analysis pa ON rd.id = pa.raw_data_id
            WHERE rd.timestamp >= NOW() - INTERVAL '30 days'
            GROUP BY DATE(rd.timestamp)
            ORDER BY date
        """
        
        df = pd.read_sql(query, self.db)
        
        fig = px.line(df, x='date', y='avg_score',
                     title='EvoluciÃ³n del Sentimiento - Ãšltimos 30 dÃ­as',
                     labels={'avg_score': 'PuntuaciÃ³n Promedio'})
        
        st.plotly_chart(fig, use_container_width=True)
    
    def render_topic_distribution(self):
        """
        Muestra distribuciÃ³n de temas identificados
        """
        query = """
            SELECT topic_cluster, COUNT(*) as count
            FROM processed_analysis
            WHERE topic_cluster IS NOT NULL
            GROUP BY topic_cluster
        """
        
        df = pd.read_sql(query, self.db)
        
        fig = px.pie(df, values='count', names='topic_cluster',
                    title='DistribuciÃ³n de Temas Identificados')
        
        st.plotly_chart(fig, use_container_width=True)
```

### 5. Sistema de Alertas

```python
# Sistema de detecciÃ³n y notificaciÃ³n de alertas
class AlertSystem:
    def __init__(self, db_connection):
        self.db = db_connection
        self.thresholds = {
            'sentiment_negative': -0.5,
            'mention_spike': 50,
            'critical_keywords': ['crisis', 'problema', 'urgente']
        }
    
    def detect_sentiment_alerts(self):
        """
        Detecta caÃ­das significativas en sentimiento
        """
        query = """
            SELECT AVG(sentiment_score) as avg_score
            FROM processed_analysis
            WHERE processed_at >= NOW() - INTERVAL '24 hours'
        """
        
        result = pd.read_sql(query, self.db)
        avg_score = result['avg_score'][0]
        
        if avg_score < self.thresholds['sentiment_negative']:
            self.create_alert(
                pattern_type='sentiment_drop',
                description=f'CaÃ­da de sentimiento detectada: {avg_score:.2f}',
                severity='high'
            )
    
    def create_alert(self, pattern_type, description, severity):
        """
        Registra nueva alerta en base de datos
        """
        query = """
            INSERT INTO detected_patterns 
            (pattern_type, description, severity_level)
            VALUES (%s, %s, %s)
        """
        
        cursor = self.db.cursor()
        cursor.execute(query, (pattern_type, description, severity))
        self.db.commit()
        
        # NotificaciÃ³n por email
        self.send_notification(pattern_type, description, severity)
```

## ðŸ› ï¸ TecnologÃ­as Utilizadas

- **Backend**: Python 3.9+
- **Base de Datos**: PostgreSQL
- **IA/ML**: scikit-learn, transformers, spaCy
- **VisualizaciÃ³n**: Streamlit, Plotly
- **OSINT**: BeautifulSoup, Selenium, APIs oficiales
- **NLP**: BERT multilingual, anÃ¡lisis de sentimientos

## ðŸ“¦ InstalaciÃ³n

```bash
# Clonar repositorio
git clone https://github.com/Darkweaver2535/SISTEMA_ANALITICA_EMI.git
cd SISTEMA_ANALITICA_EMI

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Configurar base de datos
psql -U postgres -f database/schema.sql
```

## ðŸš€ Uso

```bash
# Iniciar recolecciÃ³n de datos
python src/collectors/osint_collector.py

# Procesar datos con IA
python src/processors/nlp_analyzer.py

# Lanzar dashboard
streamlit run src/dashboard/app.py
```

## ðŸ“Š Resultados Esperados

- ReducciÃ³n del 70% en tiempo de anÃ¡lisis manual
- IdentificaciÃ³n automÃ¡tica de patrones en tiempo real
- Dashboard interactivo con mÃ©tricas clave
- Sistema de alertas tempranas

## ðŸŽ“ Contexto Institucional

### Escuela Militar de IngenierÃ­a

La Escuela Militar de IngenierÃ­a "Mariscal Antonio JosÃ© de Sucre" fue creada mediante Decreto Supremo No 2229 del 29 de Octubre de 1950, con la misiÃ³n de formar profesionales de excelencia en ingenierÃ­a.

#### MisiÃ³n
Formar y especializar profesionales de excelencia, con principios, valores Ã©tico-morales y cÃ­vicos, caracterizados por su responsabilidad social, espÃ­ritu emprendedor, liderazgo y disciplina; promoviendo la internacionalizaciÃ³n, InteracciÃ³n Social y desarrollo de la Ciencia, TecnologÃ­a e InnovaciÃ³n, para contribuir al desarrollo del Estado.

#### VisiÃ³n
Ser la Universidad lÃ­der en la formaciÃ³n de profesionales en IngenierÃ­a y de especializaciÃ³n, caracterizada por el estudio, aplicaciÃ³n e innovaciÃ³n tecnolÃ³gica, con responsabilidad social y reconocida a nivel nacional e internacional.

## ðŸ” Fundamentos TeÃ³ricos

### Open Source Intelligence (OSINT)
OSINT es la prÃ¡ctica de recolectar y analizar informaciÃ³n obtenida exclusivamente de fuentes abiertas y disponibles pÃºblicamente para apoyar actividades de inteligencia. El sistema implementa tÃ©cnicas OSINT para:

- RecolecciÃ³n automatizada de datos de redes sociales
- AnÃ¡lisis de fuentes pÃºblicas institucionales
- Monitoreo de tendencias y percepciones
- IdentificaciÃ³n de patrones de comportamiento

### Inteligencia Artificial
El sistema utiliza IA para el procesamiento automÃ¡tico de datos no estructurados mediante:

- **Procesamiento de Lenguaje Natural (NLP)**: AnÃ¡lisis de sentimientos y extracciÃ³n de entidades
- **Machine Learning**: Clustering y clasificaciÃ³n de datos
- **Deep Learning**: Redes neuronales para reconocimiento de patrones

## ðŸ“ˆ Alcances

### Alcance TemÃ¡tico
- **Ãrea General**: IngenierÃ­a de Sistemas
- **Ãrea de InvestigaciÃ³n**: GestiÃ³n del conocimiento y nuevas tecnologÃ­as
- **LÃ­nea de InvestigaciÃ³n**: Nuevas TecnologÃ­as

### Alcance GeogrÃ¡fico
Escuela Militar de IngenierÃ­a - Unidad AcadÃ©mica La Paz (UALP), Bolivia

### Alcance Temporal
GestiÃ³n II/2025 - I/2026

## âš ï¸ LÃ­mites del Sistema

- Monitoreo de mÃ¡ximo 3 plataformas digitales principales
- AnÃ¡lisis enfocado en percepciÃ³n institucional y tendencias generales
- Procesamiento de informaciÃ³n de los Ãºltimos 6 meses

## ðŸ“š MetodologÃ­a

**Tipo de InvestigaciÃ³n**: InvestigaciÃ³n Aplicada  
**Enfoque**: Descriptivo con elementos cualitativos y cuantitativos  
**MÃ©todo**: ObservaciÃ³n y descripciÃ³n de fenÃ³menos para identificar patrones

## ðŸ‘¥ Autor

**Alvaro Encinas**  
Estudiante de IngenierÃ­a de Sistemas  
Escuela Militar de IngenierÃ­a - UALP  
GestiÃ³n II/2025 - I/2026

## ðŸ“„ Licencia

Este proyecto es desarrollado como Trabajo de Grado para la Escuela Militar de IngenierÃ­a.

## ðŸ™ Agradecimientos

Al Vicerrectorado de Grado de la Escuela Militar de IngenierÃ­a por el apoyo y colaboraciÃ³n en el desarrollo de este proyecto.

---

**Escuela Militar de IngenierÃ­a "Mcal. Antonio JosÃ© de Sucre"**  
*Formando profesionales de excelencia con valores Ã©tico-morales*
